{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis for Social Media Comments\n",
    "\n",
    "This notebook performs sentiment analysis on comments scraped from TikTok and Instagram.\n",
    "It includes:\n",
    "- Data loading and preprocessing\n",
    "- Sentiment analysis using TextBlob\n",
    "- Word cloud generation\n",
    "- Sentiment distribution visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "from textblob import TextBlob\n",
    "import re\n",
    "import os\n",
    "from collections import Counter\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Set style for matplotlib\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Configure pandas display\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\"Load data from both TikTok and Instagram scrapers\"\"\"\n",
    "    data_frames = []\n",
    "    \n",
    "    # Load TikTok data\n",
    "    tiktok_path = '../data/tiktok/all_comments.csv'\n",
    "    if os.path.exists(tiktok_path):\n",
    "        tiktok_df = pd.read_csv(tiktok_path)\n",
    "        tiktok_df['platform'] = 'TikTok'\n",
    "        tiktok_df['text'] = tiktok_df.get('comment', '')\n",
    "        data_frames.append(tiktok_df)\n",
    "        print(f\"Loaded {len(tiktok_df)} TikTok comments\")\n",
    "    else:\n",
    "        print(\"TikTok data not found\")\n",
    "    \n",
    "    # Load Instagram data\n",
    "    instagram_path = '../data/instagram/all_comments.csv'\n",
    "    if os.path.exists(instagram_path):\n",
    "        instagram_df = pd.read_csv(instagram_path)\n",
    "        instagram_df['platform'] = 'Instagram'\n",
    "        instagram_df['text'] = instagram_df.get('comment_text', '')\n",
    "        data_frames.append(instagram_df)\n",
    "        print(f\"Loaded {len(instagram_df)} Instagram comments\")\n",
    "    else:\n",
    "        print(\"Instagram data not found\")\n",
    "    \n",
    "    if data_frames:\n",
    "        combined_df = pd.concat(data_frames, ignore_index=True)\n",
    "        return combined_df\n",
    "    else:\n",
    "        print(\"No data found. Please run the scrapers first.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Load the data\n",
    "df = load_data()\n",
    "print(f\"\\nTotal comments loaded: {len(df)}\")\n",
    "if not df.empty:\n",
    "    print(f\"Platforms: {df['platform'].value_counts().to_dict()}\")\n",
    "    print(f\"\\nData shape: {df.shape}\")\n",
    "    print(f\"\\nColumns: {list(df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"Clean and preprocess text for analysis\"\"\"\n",
    "    if pd.isna(text) or text == '':\n",
    "        return ''\n",
    "    \n",
    "    # Convert to string\n",
    "    text = str(text)\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    \n",
    "    # Remove mentions and hashtags for sentiment analysis (but keep the text)\n",
    "    text = re.sub(r'@\\w+|#\\w+', '', text)\n",
    "    \n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Clean the text data\n",
    "if not df.empty:\n",
    "    df['cleaned_text'] = df['text'].apply(clean_text)\n",
    "    \n",
    "    # Remove empty comments\n",
    "    df = df[df['cleaned_text'].str.len() > 0]\n",
    "    \n",
    "    print(f\"After cleaning: {len(df)} comments\")\n",
    "    print(f\"Sample cleaned comments:\")\n",
    "    print(df['cleaned_text'].head().tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment(text):\n",
    "    \"\"\"Analyze sentiment using TextBlob\"\"\"\n",
    "    if not text or text.strip() == '':\n",
    "        return 0, 0, 'neutral'\n",
    "    \n",
    "    blob = TextBlob(text)\n",
    "    polarity = blob.sentiment.polarity\n",
    "    subjectivity = blob.sentiment.subjectivity\n",
    "    \n",
    "    # Classify sentiment\n",
    "    if polarity > 0.1:\n",
    "        sentiment = 'positive'\n",
    "    elif polarity < -0.1:\n",
    "        sentiment = 'negative'\n",
    "    else:\n",
    "        sentiment = 'neutral'\n",
    "    \n",
    "    return polarity, subjectivity, sentiment\n",
    "\n",
    "# Perform sentiment analysis\n",
    "if not df.empty:\n",
    "    print(\"Performing sentiment analysis...\")\n",
    "    \n",
    "    sentiment_results = df['cleaned_text'].apply(analyze_sentiment)\n",
    "    df[['polarity', 'subjectivity', 'sentiment']] = pd.DataFrame(sentiment_results.tolist(), index=df.index)\n",
    "    \n",
    "    print(\"Sentiment analysis completed!\")\n",
    "    print(f\"\\nSentiment distribution:\")\n",
    "    print(df['sentiment'].value_counts())\n",
    "    \n",
    "    print(f\"\\nAverage polarity: {df['polarity'].mean():.3f}\")\n",
    "    print(f\"Average subjectivity: {df['subjectivity'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Word Cloud Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_wordcloud(text_data, title=\"Word Cloud\", max_words=100):\n",
    "    \"\"\"Create and display word cloud\"\"\"\n",
    "    if not text_data:\n",
    "        print(\"No text data available for word cloud\")\n",
    "        return\n",
    "    \n",
    "    # Combine all text\n",
    "    all_text = ' '.join(text_data)\n",
    "    \n",
    "    # Create word cloud\n",
    "    wordcloud = WordCloud(\n",
    "        width=800, \n",
    "        height=400, \n",
    "        background_color='white',\n",
    "        max_words=max_words,\n",
    "        colormap='viridis'\n",
    "    ).generate(all_text)\n",
    "    \n",
    "    # Display\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title(title, fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "if not df.empty:\n",
    "    # Overall word cloud\n",
    "    create_wordcloud(df['cleaned_text'].tolist(), \"Overall Comments Word Cloud\")\n",
    "    \n",
    "    # Word clouds by sentiment\n",
    "    for sentiment in ['positive', 'negative', 'neutral']:\n",
    "        sentiment_texts = df[df['sentiment'] == sentiment]['cleaned_text'].tolist()\n",
    "        if sentiment_texts:\n",
    "            create_wordcloud(sentiment_texts, f\"{sentiment.title()} Comments Word Cloud\")\n",
    "    \n",
    "    # Word clouds by platform\n",
    "    for platform in df['platform'].unique():\n",
    "        platform_texts = df[df['platform'] == platform]['cleaned_text'].tolist()\n",
    "        if platform_texts:\n",
    "            create_wordcloud(platform_texts, f\"{platform} Comments Word Cloud\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Sentiment Distribution Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df.empty:\n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # 1. Overall sentiment distribution\n",
    "    sentiment_counts = df['sentiment'].value_counts()\n",
    "    axes[0, 0].pie(sentiment_counts.values, labels=sentiment_counts.index, autopct='%1.1f%%', startangle=90)\n",
    "    axes[0, 0].set_title('Overall Sentiment Distribution')\n",
    "    \n",
    "    # 2. Sentiment by platform\n",
    "    sentiment_platform = pd.crosstab(df['platform'], df['sentiment'])\n",
    "    sentiment_platform.plot(kind='bar', ax=axes[0, 1], rot=45)\n",
    "    axes[0, 1].set_title('Sentiment Distribution by Platform')\n",
    "    axes[0, 1].legend(title='Sentiment')\n",
    "    \n",
    "    # 3. Polarity distribution\n",
    "    axes[1, 0].hist(df['polarity'], bins=30, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "    axes[1, 0].axvline(df['polarity'].mean(), color='red', linestyle='--', label=f'Mean: {df[\"polarity\"].mean():.3f}')\n",
    "    axes[1, 0].set_title('Polarity Distribution')\n",
    "    axes[1, 0].set_xlabel('Polarity Score')\n",
    "    axes[1, 0].set_ylabel('Frequency')\n",
    "    axes[1, 0].legend()\n",
    "    \n",
    "    # 4. Subjectivity distribution\n",
    "    axes[1, 1].hist(df['subjectivity'], bins=30, alpha=0.7, color='lightcoral', edgecolor='black')\n",
    "    axes[1, 1].axvline(df['subjectivity'].mean(), color='blue', linestyle='--', label=f'Mean: {df[\"subjectivity\"].mean():.3f}')\n",
    "    axes[1, 1].set_title('Subjectivity Distribution')\n",
    "    axes[1, 1].set_xlabel('Subjectivity Score')\n",
    "    axes[1, 1].set_ylabel('Frequency')\n",
    "    axes[1, 1].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Interactive Visualizations with Plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df.empty:\n",
    "    # Interactive sentiment distribution by platform\n",
    "    fig = px.sunburst(\n",
    "        df, \n",
    "        path=['platform', 'sentiment'], \n",
    "        title='Sentiment Distribution by Platform (Interactive)'\n",
    "    )\n",
    "    fig.show()\n",
    "    \n",
    "    # Scatter plot: Polarity vs Subjectivity\n",
    "    fig = px.scatter(\n",
    "        df, \n",
    "        x='polarity', \n",
    "        y='subjectivity', \n",
    "        color='sentiment',\n",
    "        hover_data=['platform', 'username'],\n",
    "        title='Polarity vs Subjectivity by Sentiment'\n",
    "    )\n",
    "    fig.show()\n",
    "    \n",
    "    # Box plot of polarity by platform\n",
    "    fig = px.box(\n",
    "        df, \n",
    "        x='platform', \n",
    "        y='polarity', \n",
    "        color='platform',\n",
    "        title='Polarity Distribution by Platform'\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Detailed Analysis and Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df.empty:\n",
    "    print(\"=== SENTIMENT ANALYSIS SUMMARY ===\")\n",
    "    print(f\"\\nTotal comments analyzed: {len(df)}\")\n",
    "    \n",
    "    # Platform breakdown\n",
    "    print(\"\\n--- Platform Breakdown ---\")\n",
    "    platform_stats = df.groupby('platform').agg({\n",
    "        'sentiment': lambda x: x.value_counts().to_dict(),\n",
    "        'polarity': ['mean', 'std'],\n",
    "        'subjectivity': ['mean', 'std']\n",
    "    })\n",
    "    print(platform_stats)\n",
    "    \n",
    "    # Sentiment statistics\n",
    "    print(\"\\n--- Sentiment Statistics ---\")\n",
    "    sentiment_stats = df.groupby('sentiment').agg({\n",
    "        'polarity': ['count', 'mean', 'std', 'min', 'max'],\n",
    "        'subjectivity': ['mean', 'std']\n",
    "    })\n",
    "    print(sentiment_stats)\n",
    "    \n",
    "    # Most common words by sentiment\n",
    "    print(\"\\n--- Most Common Words by Sentiment ---\")\n",
    "    for sentiment in ['positive', 'negative', 'neutral']:\n",
    "        sentiment_text = ' '.join(df[df['sentiment'] == sentiment]['cleaned_text'])\n",
    "        words = re.findall(r'\\b\\w+\\b', sentiment_text.lower())\n",
    "        common_words = Counter(words).most_common(10)\n",
    "        print(f\"\\n{sentiment.upper()} - Top 10 words:\")\n",
    "        for word, count in common_words:\n",
    "            print(f\"  {word}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df.empty:\n",
    "    # Save analyzed data\n",
    "    output_path = '../data/sentiment_analysis_results.csv'\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"Results saved to: {output_path}\")\n",
    "    \n",
    "    # Create summary statistics file\n",
    "    summary_stats = {\n",
    "        'total_comments': len(df),\n",
    "        'platform_distribution': df['platform'].value_counts().to_dict(),\n",
    "        'sentiment_distribution': df['sentiment'].value_counts().to_dict(),\n",
    "        'average_polarity': df['polarity'].mean(),\n",
    "        'average_subjectivity': df['subjectivity'].mean(),\n",
    "        'polarity_by_platform': df.groupby('platform')['polarity'].mean().to_dict(),\n",
    "        'sentiment_by_platform': df.groupby(['platform', 'sentiment']).size().to_dict()\n",
    "    }\n",
    "    \n",
    "    summary_path = '../data/sentiment_summary.json'\n",
    "    with open(summary_path, 'w') as f:\n",
    "        json.dump(summary_stats, f, indent=2)\n",
    "    \n",
    "    print(f\"Summary statistics saved to: {summary_path}\")\n",
    "    print(\"\\nAnalysis complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
